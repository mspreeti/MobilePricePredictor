import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("train.csv")

df.head()

#We are getting info on the features- 20 features to decide the price range. Output feature is price_range. Next we need to understand how many unique values are
# for the output:price_range 
df.info()

df['price_range'].unique()

df['price_range'].value_counts()

df_test = pd.read_csv("test.csv")

df_test.head()

#Lets dwelve into the kind of information the data. 1. Check for missing data. The info shows that there are non-null data. Hence, we can proceed.
#2. Now we shall check for the correlation between the features. Result: High corr:Ram with price_range. PC and FC, Sc_h and sc_w, px_width to px_height
# four_g to three_g. There is only one feature that shows positive correlation to Price range. All the other results seem that we can use only 1 feature and let go of the other.
corr_matrix = df.corr().round(2)
fig, ax = plt.subplots(figsize=(15,10)) 
heat = sns.heatmap(data=corr_matrix,annot=True)



#This step shall help in getting the top 4 features having correlation to output variable i.e. Price_range: ram, battery_power, px_width, px_height
b = corr_matrix.sort_values(by='price_range',ascending=False)
b

sns.catplot(x='price_range',kind='count',data=df)

##MODEL BUILDING: with features that affect the price most: Ram
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

X = pd.DataFrame(np.c_[df['ram'],df['px_height'],df['battery_power'],df['px_width']],columns = ['ram','px_height','battery_power','px_width'])
Y = df['price_range']

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state=5)
print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)



model1 = LinearRegression()
model1.fit(X_train,Y_train)


# Model Evaluation for training set
y_train_predict = model1.predict(X_train)
rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))
r2 = r2_score(Y_train, y_train_predict)

print('RMSE for training data is {}'.format(rmse))
print('R2 score for training data is {}'.format(r2))
print("\n")

# model evaluation for testing set
y_test_predict = model1.predict(X_test)
rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))
r2 = r2_score(Y_test, y_test_predict)

print('RMSE for testing data is {}'.format(rmse))
print('R2 score for testing data is {}'.format(r2))

#print(model1.coef_)
print("The model intercept is: ",model1.intercept_)




error = Y_test - y_test_predict
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error [Price]")
_ = plt.ylabel("Count")

##LINEAR REG MODEL WITH ALL FEATURES:

from sklearn.model_selection import train_test_split
from sklearn import linear_model

X = pd.DataFrame(df)
Y = df['price_range']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state=5)
print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)

model = linear_model.LinearRegression()
model.fit(X_train,Y_train)

# Model Evaluation for training set
Y_pred_train1 = model.predict(X_train)
Y_pred = model.predict(X_test)

Z = pd.DataFrame(df_test)
Y_predictions = model.predict(Z)
print("The predictions on test.csv data file are: " , Y_predictions)


r2_train = r2_score(Y_train, Y_pred_train1)
rmse5 = np.sqrt(mean_squared_error(Y_train, Y_pred_train1))
print ("The Root Mean Squared Error for Training model is:", rmse5)
print("The R-Squared value for training model is:", r2_train)

r2 = r2_score(Y_test, Y_pred)
rmse6 = np.sqrt(mean_squared_error(Y_test,Y_pred))
print ("The Mean Squared Error for Testing model is:", rmse6)
print("The R-Squared value for testing model is:", r2)
